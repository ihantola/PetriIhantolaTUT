@inproceedings{Brusilovsky:2014:IAS:2713609.2713611,
 author = {Brusilovsky, Peter and Edwards, Stephen and Kumar, Amruth and Malmi, Lauri and Benotti, Luciana and Buck, Duane and Ihantola, Petri and Prince, Rikki and Sirki\"{a}, Teemu and Sosnovsky, Sergey and Urquiza, Jaime and Vihavainen, Arto and Wollowski, Michael},
 title = {Increasing Adoption of Smart Learning Content for Computer Science Education},
 booktitle = {Proceedings of the Working Group Reports of the 2014 on Innovation \&\#38; Technology in Computer Science Education Conference},
 series = {ITiCSE-WGR '14},
 year = {2014},
 isbn = {978-1-4503-3406-8},
 location = {Uppsala, Sweden},
 pages = {31--57},
 numpages = {27},
 url = {http://doi.acm.org/10.1145/2713609.2713611},
 doi = {10.1145/2713609.2713611},
 acmid = {2713611},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {classroom management, computer science education, dissemination, educational research, educational tools, intelligent tutoring systems, smart learning content, teaching with technology, technology adoption, technology integration},
 abstract={Computer science educators are increasingly using interactive learning content to enrich and enhance the pedagogy of their courses. A plethora of such learning content, specifically designed for computer science education, such as visualization, simulation, and web-based environments for learning programming, are now available for various courses. We call such content smart learning content. However, such learning content is seldom used outside its host site despite the benefits it could offer to learners everywhere. In this paper, we investigate the factors that impede dissemination of such content among the wider computer science education community. To accomplish this we surveyed educators, existing tools and recent research literature to identify the current state of the art and analyzed the characteristics of a large number of smart learning content examples along canonical dimensions. In our analysis we focused on examining the technical issues that must be resolved to support finding, integrating and customizing smart learning content in computer science courses. Finally, we propose a new architecture for hosting, integrating and disseminating smart learning content and discuss how it could be implemented based on existing protocols and standards.},
} 

@inproceedings{Vihavainen:2014:ASC:2656450.2656473,
 author = {Vihavainen, Arto and Luukkainen, Matti and Ihantola, Petri},
 title = {Analysis of Source Code Snapshot Granularity Levels},
 booktitle = {Proceedings of the 15th Annual Conference on Information Technology Education},
 series = {SIGITE '14},
 year = {2014},
 isbn = {978-1-4503-2686-5},
 location = {Atlanta, Georgia, USA},
 pages = {21--26},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2656450.2656473},
 doi = {10.1145/2656450.2656473},
 acmid = {2656473},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data collection, fine-grained data analysis, programming education, programming process, programming snapshots, source code, source code snapshots, source code submissions},
 abstract = {Systems that record students' programming process have become increasingly popular during the last decade. The granularity of stored data varies across these systems and ranges from storing the final state, e.g. a solution, to storing fine-grained event streams, e.g. every key-press made while working on a task. Researchers that study such data make assumptions based on the granularity. If no fine-grained data exists, the baseline assumption is that a student proceeds in a linear fashion from one recorded state to the next. In this work, we analyze three different granularities of data; (1) submissions, (2) snapshots (i.e. save, compile, run, test events), and (3) keystroke-events. Our study provides insight on the quantity of lost data when storing data at a specific granularity and shows how the lost data varies depending on previous programming experience and the programming assignment type.},
} 

@inproceedings{Ihantola:2013:SPM:2526968.2526974,
 author = {Ihantola, Petri and Helminen, Juha and Karavirta, Ville},
 title = {How to Study Programming on Mobile Touch Devices: Interactive Python Code Exercises},
 booktitle = {Proceedings of the 13th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '13},
 year = {2013},
 isbn = {978-1-4503-2482-3},
 location = {Koli, Finland},
 pages = {51--58},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2526968.2526974},
 doi = {10.1145/2526968.2526974},
 acmid = {2526974},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Python, learning, mLearning, mobile learning, mobile touch devices, parsons problem, parsons puzzle, programming, teaching},
 abstract={Scaffolded learning tasks where programs are constructed from predefined code fragments by dragging and dropping them (i.e. Parsons problems) are well suited to mobile touch devices, but quite limited in their applicability. They do not adequately cater for different approaches to constructing a program. After studying solutions to automatically assessed programming exercises, we found out that many different solutions are composed of a relatively small set of mutually similar code lines. Thus, they can be constructed by using the drag-and-drop approach if only it was possible to edit some small parts of the predefined fragments. Based on this, we have designed and implemented a new exercise type for mobile devices that builds on Parsons problems and falls somewhere between their strict scaffolding and full-blown coding exercises. In these exercises, we can gradually fade the scaffolding and allow programs to be constructed more freely so as not to restrict thinking and limit creativity too much while still making sure we are able to deploy them to small-screen mobile devices. In addition to the new concept and the related implementation, we discuss other possibilities of how programming could be practiced on mobile devices.},
} 

@inproceedings{Vihavainen:2014:NTF:2674683.2674692,
 author = {Vihavainen, Arto and Helminen, Juha and Ihantola, Petri},
 title = {How Novices Tackle Their First Lines of Code in an IDE: Analysis of Programming Session Traces},
 booktitle = {Proceedings of the 14th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '14},
 year = {2014},
 isbn = {978-1-4503-3065-7},
 location = {Koli, Finland},
 pages = {109--116},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2674683.2674692},
 doi = {10.1145/2674683.2674692},
 acmid = {2674692},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data mining, introductory programming, learning analytics, novice programmers, novices and programming environments, programming behavior, programming environments, programming session trace analysis, source code snapshot analysis},
 abstract={While computing educators have put plenty of effort into researching and developing programming environments that make it easier for students to create their first programs, these tools often have only little resemblance with the tools used in the industry. We report on a study, where students with no previous programming experience started to program directly using an industry strength programming environment. The programming environment was augmented with logging capability that recorded every keystroke and event within the system, which provided a view on how the novices tackle their first lines of code. Our results show that while at first, the students struggle with syntax - as is typical with learning a new language - no evidence can be found that suggests that learning to use the programming environment is hard. In a two-week period, the students learned to use the basic features of the programming environment such as specific shortcuts. Although we observed students using copy-paste-programming relatively often, most of the pasted code is from their own previous work. Finally, when considering the compilation errors and error distributions, we hypothesize that the errors are a product of three factors; the exercises, the environment, and the data logging granularity.},
}

@inproceedings{Busjahn:2014:ETC:2632320.2632344,
 author = {Busjahn, Teresa and Schulte, Carsten and Sharif, Bonita and Simon and Begel, Andrew and Hansen, Michael and Bednarik, Roman and Orlov, Paul and Ihantola, Petri and Shchekotova, Galina and Antropova, Maria},
 title = {Eye Tracking in Computing Education},
 booktitle = {Proceedings of the Tenth Annual Conference on International Computing Education Research},
 series = {ICER '14},
 year = {2014},
 isbn = {978-1-4503-2755-8},
 location = {Glasgow, Scotland, United Kingdom},
 pages = {3--10},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2632320.2632344},
 doi = {10.1145/2632320.2632344},
 acmid = {2632344},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {code reading, computing education, cs ed research, empirical research, eye tracking, gaze analysis, program comprehension, programming education, teaching programming},
 abstract={The methodology of eye tracking has been gradually making its way into various fields of science, assisted by the diminishing cost of the associated technology. In an international collaboration to open up the prospect of eye movement research for programming educators, we present a case study on program comprehension and preliminary analyses together with some useful tools.

The main contributions of this paper are (1) an introduction to eye tracking to study programmers; (2) an approach that can help elucidate how novices learn to read and understand programs and to identify improvements to teaching and tools; (3) a consideration of data analysis methods and challenges, along with tools to address them; and (4) some larger computing education questions that can be addressed (or revisited) in the context of eye tracking.},
}

@inproceedings{Karavirta:2012:MLA:2401796.2401798,
 author = {Karavirta, Ville and Helminen, Juha and Ihantola, Petri},
 title = {A Mobile Learning Application for Parsons Problems with Automatic Feedback},
 booktitle = {Proceedings of the 12th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '12},
 year = {2012},
 isbn = {978-1-4503-1795-5},
 location = {Koli, Finland},
 pages = {11--18},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2401796.2401798},
 doi = {10.1145/2401796.2401798},
 acmid = {2401798},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Parsons problem, Parsons puzzle, Python, mLearning, mobile learning},
 abstract={In this paper, we present a tool that facilitates the learning of programming by providing a mobile application for Parsons problems. These are small assignments where learners build programs by ordering and indenting fragments of code. Parsons problems are well-suited to the mobile context as the assignments form small chunks of learning content that individually require little time to go through and may be freely divided across multiple learning sessions. Furthermore, in response to previous analysis of students using a web environment for Parsons problems, we describe improvements to the automatic feedback given in these assignments},
 note={Best paper award},
}

@inproceedings{Ihantola:2014:ADI:2656450.2656476,
 author = {Ihantola, Petri and Sorva, Juha and Vihavainen, Arto},
 title = {Automatically Detectable Indicators of Programming Assignment Difficulty},
 booktitle = {Proceedings of the 15th Annual Conference on Information Technology Education},
 series = {SIGITE '14},
 year = {2014},
 isbn = {978-1-4503-2686-5},
 location = {Atlanta, Georgia, USA},
 pages = {33--38},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2656450.2656476},
 doi = {10.1145/2656450.2656476},
 acmid = {2656476},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assignment difficulty, automated assessment, personalized feedback, programming assignments},
 abstract={The difficulty of learning tasks is a major factor in learning, as is the feedback given to students. Even automatic feedback should ideally be influenced by student-dependent factors such as task difficulty. We report on a preliminary exploration of such indicators of programming assignment difficulty that can be automatically detected for each student from source code snapshots of the student's evolving code. Using a combination of different metrics emerged as a promising approach. In the future, our results may help provide students with personalized automatic feedback.},
 note={Best paper award},
} 

@inproceedings{Helminen:2013:RAI:2526968.2526970,
 author = {Helminen, Juha and Ihantola, Petri and Karavirta, Ville},
 title = {Recording and Analyzing In-browser Programming Sessions},
 booktitle = {Proceedings of the 13th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '13},
 year = {2013},
 isbn = {978-1-4503-2482-3},
 location = {Koli, Finland},
 pages = {13--22},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2526968.2526970},
 doi = {10.1145/2526968.2526970},
 acmid = {2526970},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Python, computer science education, computing education research, programming assignment, programming session, web based programming environment},
 abstract={In this paper, we report on the analysis of a novel type of automatically recorded detailed programming session data collected on a university-level web programming course. We present a method and an implementation of collecting rich data on how students learning to program edit and execute code and explore its use in examining learners' behavior. The data collection instrument is an in-browser Python programming environment that integrates an editor, an execution environment, and an interactive Python console and is used to deliver programming assignments with automatic feedback. Most importantly, the environment records learners' interaction within it. We have implemented tools for viewing these traces and demonstrate their potential in learning about the programming processes of learners and of benefiting computing education research and the teaching of programming.},
 note={Computing Reviews' Best of 2013},
}

@inproceedings{Ihantola:2010:RRS:1930464.1930480,
 author = {Ihantola, Petri and Ahoniemi, Tuukka and Karavirta, Ville and Sepp\"{a}l\"{a}, Otto},
 title = {Review of Recent Systems for Automatic Assessment of Programming Assignments},
 booktitle = {Proceedings of the 10th Koli Calling International Conference on Computing Education Research},
 series = {Koli Calling '10},
 year = {2010},
 isbn = {978-1-4503-0520-4},
 location = {Koli, Finland},
 pages = {86--93},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1930464.1930480},
 doi = {10.1145/1930464.1930480},
 acmid = {1930480},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstact={This paper presents a systematic literature review of the recent (2006--2010) development of automatic assessment tools for programming exercises. We discuss the major features that the tools support and the different approaches they are using both from the pedagogical and the technical point of view. Examples of these features are ways for the teacher to define tests, resubmission policies, security issues, and so forth. We have also identified a list of novel features, like assessing web software, that are likely to get more research attention in the future. As a conclusion, we state that too many new systems are developed, but also acknowledge the current reasons for the phenomenon. As one solution we encourage opening up the existing systems and joining efforts on developing those further. Selected systems from our survey are briefly described in Appendix A.},
} 

@inproceedings{Helminen:2012:SSP:2361276.2361300,
 author = {Helminen, Juha and Ihantola, Petri and Karavirta, Ville and Malmi, Lauri},
 title = {How Do Students Solve Parsons Programming Problems?: An Analysis of Interaction Traces},
 booktitle = {Proceedings of the Ninth Annual International Conference on International Computing Education Research},
 series = {ICER '12},
 year = {2012},
 isbn = {978-1-4503-1604-0},
 location = {Auckland, New Zealand},
 pages = {119--126},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2361276.2361300},
 doi = {10.1145/2361276.2361300},
 acmid = {2361300},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {parsons puzzles, problem solving process, python},
 abstract={The process of solving a programming assignment is generally invisible to the teacher. We only see the end result and maybe a few snapshots along the way. In order to investigate this process with regard to Parsons problems, we used an online environment for Parsons problems in Python to record a detailed trace of all the interaction during the solving session. In these assignments, learners are to correctly order and indent a given set of code fragments in order to build a functioning program that meets the set requirements. We collected data from students of two programming courses and among other analyses present a visualization of the solution path as an interactive graph that can be used to explore such patterns and anomalies as backtracking and loops in the solution. The results provide insights into students' solving process for these types of problems and ideas on how to improve the assignment environment and its use in programming education.}, 
}

@inproceedings{Haaranen:2014:IBO:2538862.2538921,
 author = {Haaranen, Lassi and Ihantola, Petri and Hakulinen, Lasse and Korhonen, Ari},
 title = {How (Not) to Introduce Badges to Online Exercises},
 booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
 series = {SIGCSE '14},
 year = {2014},
 isbn = {978-1-4503-2605-6},
 location = {Atlanta, Georgia, USA},
 pages = {33--38},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2538862.2538921},
 doi = {10.1145/2538862.2538921},
 acmid = {2538921},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {achievement badges, computer science education, gamification},
 abstract={Achievement badges are increasingly used to enhance educational systems and they have been shown to affect student behavior in different ways. However, details on best practices and effective concepts to implement badges from a non-technical point of view are scarce. We implemented badges to our learning management system, used them on a large course and collected feedback from students. Based on our experiences, we present recommendations to other educators that plan on using badges.},
} 

@inproceedings{RoBling:2010:AMB:1971681.1971684,
 author = {R\"{o}\ssling, Guido and McNally, Myles and Crescenzi, Pierluigi and Radenski, Atanas and Ihantola, Petri and S\'{a}nchez-Torrubia, M. Gloria},
 title = {Adapting Moodle to Better Support CS Education},
 booktitle = {Proceedings of the 2010 ITiCSE Working Group Reports},
 series = {ITiCSE-WGR '10},
 year = {2010},
 isbn = {978-1-4503-0677-5},
 location = {Ankara, Turkey},
 pages = {15--27},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/1971681.1971684},
 doi = {10.1145/1971681.1971684},
 acmid = {1971684},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CALMS, LMS, Moodle, computer science education, computing augmented learning management system, learning management system},
 abstract={Many commercial or open-source systems for organizing courses are available, offering access to course materials, communication support, and receiving and grading student submissions. However, most of these systems are by default not ideally prepared to address specific demands of Computer Science (CS) education. We explore how Moodle as one of the most popular and free systems can be better adapted to support the needs of CS education and provide concrete guidance on features and extensions that could be explored. This report and work based on it can significantly improve courses for educators and students alike},
} 

@inproceedings{Ihantola:2005:TEC:1089786.1089798,
 author = {Ihantola, Petri and Karavirta, Ville and Korhonen, Ari and Nikander, Jussi},
 title = {Taxonomy of Effortless Creation of Algorithm Visualizations},
 booktitle = {Proceedings of the First International Workshop on Computing Education Research},
 series = {ICER '05},
 year = {2005},
 isbn = {1-59593-043-4},
 location = {Seattle, WA, USA},
 pages = {123--133},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1089786.1089798},
 doi = {10.1145/1089786.1089798},
 acmid = {1089798},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {algorithm visualization, effortlessness, interaction},
 abstract={The idea of using visualization technology to enhance the understanding of abstract concepts, like data structures and algorithms, has become widely accepted. Several attempts have been made to introduce a system that levels out the burden of creating new visualizations. However, one of the main obstacles to fully taking advantage of algorithm visualization seems to be the time and effort required to design, integrate and maintain the visualizations.Effortlessness in the context of algorithm visualization is a highly subjective matter including many factors. Thus, we first introduce a taxonomy to characterize effortlessness in algorithm visualization systems. We have identified three main categories based on a survey conducted among CS educators: i) scope, i.e. how wide is the context one can apply the system to ii) integrability, i.e., how easy it is to take in use by a third party, and iii) interaction techniques, i.e., how well does the system support different use cases regularly applied by educators. We will conclude that generic and effortless visualization systems are needed. Such a system, however, needs to combine a range of characteristics implemented in many current AV systems.},
} 

@inproceedings{Ihantola:2010:OSW:1822090.1822178,
 author = {Ihantola, Petri and Karavirta, Ville},
 title = {Open Source Widget for Parson's Puzzles},
 booktitle = {Proceedings of the Fifteenth Annual Conference on Innovation and Technology in Computer Science Education},
 series = {ITiCSE '10},
 year = {2010},
 isbn = {978-1-60558-820-9},
 location = {Bilkent, Ankara, Turkey},
 pages = {302--302},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/1822090.1822178},
 doi = {10.1145/1822090.1822178},
 acmid = {1822178},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automatic assessment, cs1, parsons problems},
 note={poster},
}

@inproceedings{Ihantola:2006:TDG:1315803.1315819,
 author = {Ihantola, Petri},
 title = {Test Data Generation for Programming Exercises with Symbolic Execution in Java PathFinder},
 booktitle = {Proceedings of the 6th Baltic Sea Conference on Computing Education Research: Koli Calling 2006},
 series = {Baltic Sea '06},
 year = {2006},
 location = {Uppsala, Sweden},
 pages = {87--94},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1315803.1315819},
 doi = {10.1145/1315803.1315819},
 acmid = {1315819},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automatic assessment, symbolic execution, test data generation},
 abstract={Automatic assessment of programming exercises is typically based on testing approach. Most automatic assessment frameworks execute tests and evaluate test results automatically, but the test data generation is not automated. No matter that such test data generation techniques and tools are available.

We have researched how the Java PathFinder software model checker can be adopted to the specific needs of test data generation in automatic assessment. Practical problems considered are: How to derive test data directly from students' programs (i.e. without annotation) and how to visualize and how to abstract test data automatically for students? Interesting outcomes of our research are that with minor refinements generalized symbolic execution with lazy initialization (a test data generation algorithm implemented in PathFinder) can be used to construct test data directly from students' programs without annotation, and that intermediate results of the same algorithm can be used to provide novel visualizations of the test data.},
 note={best paper award},
} 

@inproceedings{Karavirta:2010:SAA:1822090.1822179,
 author = {Karavirta, Ville and Ihantola, Petri},
 title = {Serverless Automatic Assessment of Javascript Exercises},
 booktitle = {Proceedings of the Fifteenth Annual Conference on Innovation and Technology in Computer Science Education},
 series = {ITiCSE '10},
 year = {2010},
 isbn = {978-1-60558-820-9},
 location = {Bilkent, Ankara, Turkey},
 pages = {303--303},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/1822090.1822179},
 doi = {10.1145/1822090.1822179},
 acmid = {1822179},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automatic assessment, javascript, programming exercises},
 note={poster}
} 

@inproceedings{Aaltonen:2010:MAV:1869542.1869567,
 author = {Aaltonen, Kalle and Ihantola, Petri and Sepp\"{a}l\"{a}, Otto},
 title = {Mutation Analysis vs. Code Coverage in Automated Assessment of Students' Testing Skills},
 booktitle = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion},
 series = {OOPSLA '10},
 year = {2010},
 isbn = {978-1-4503-0240-1},
 location = {Reno/Tahoe, Nevada, USA},
 pages = {153--160},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1869542.1869567},
 doi = {10.1145/1869542.1869567},
 acmid = {1869567},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automated assessment, mutation analysis, mutation testing, programming assignments, test coverage},
 abstract={Learning to program should include learning about proper software testing. Some automatic assessment systems, e.g. Web-CAT, allow assessing student-generated test suites using coverage metrics. While this encourages testing, we have observed that sometimes students can get rewarded from high coverage although their tests are of poor quality. Exploring alternative methods of assessment, we have tested mutation analysis to evaluate students' solutions. Initial results from applying mutation analysis to real course submissions indicate that mutation analysis could be used to fix some problems of code coverage in the assessment. Combining both metrics is likely to give more accurate feedback.},
}

@article{Ihantola:2007:CVT:1322395.1322402,
 author = {Ihantola, Petri},
 title = {Creating and Visualizing Test Data from Programming Exercises},
 journal = {Informatics in education},
 issue_date = {January 2007},
 volume = {6},
 number = {1},
 month = jan,
 year = {2007},
 issn = {1648-5831},
 pages = {81--102},
 numpages = {22},
 url = {http://dl.acm.org/citation.cfm?id=1322395.1322402},
 acmid = {1322402},
 publisher = {Institute of Mathematics and Informatics},
 address = {Vilnius, Lithuania},
 keywords = {automatic assessment, computer science education, programming exercises, software visualization, test-data, testing},
 abstract={Automatic assessment of programming exercises is typically based on testing approach. Most automatic assessment frameworks execute tests and evaluate test results automatically, but the test data generation is not automated. No matter that automatic test data generation techniques and tools are available.

We have researched how the Java PathFinder software model checker can be adopted to the specific needs of test data generation in automatic assessment. Practical problems considered are: how to derive test data directly from students' programs (i.e., without annotation) and how to visualize and how to abstract test data automatically for students? Interesting outcomes of our research are that with minor refinements generalized symbolic execution with lazy initialization (a test data generation algorithm implemented in PathFinder) can be used to construct test data directly from students' programs without annotation, and that intermediate results of the same algorithm can be used to provide novel visualizations of the test data.},
}

@inproceedings{Karavirta:2013:SAI:2548546.2548648,
 author = {Karavirta, Ville and Ihantola, Petri and Koskinen, Teemu},
 title = {Service-Oriented Approach to Improve Interoperability of E-Learning Systems},
 booktitle = {Proceedings of the 2013 IEEE 13th International Conference on Advanced Learning Technologies},
 series = {ICALT '13},
 year = {2013},
 isbn = {978-0-7695-5009-1},
 pages = {341--345},
 numpages = {5},
 url = {http://dx.doi.org/10.1109/ICALT.2013.105},
 doi = {10.1109/ICALT.2013.105},
 acmid = {2548648},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {e-learning, LMS, service oriented, interoperability, automatic assessment},
 abstract={We present a design and open source implementation for a service oriented e-learning system, which utilizes external services for supporting a wide range of learning content and also offers a REST API for external clients to fetch information stored in the system. The design will separate different concerns, such as user authentication and exercise assessment, into separate services, which together form a complete e-learning environment. A key component of the design is identifying a general set of characteristics among existing exercise assessment systems, by which the assessment methods are grouped into three types: synchronous, asynchronous and static exercises.},
} 

@inproceedings{Haaranen:2014:SAI:2624952.2625255,
 author = {Haaranen, Lassi and Hakulinen, Lasse and Ihantola, Petri and Korhonen, Ari},
 title = {Software Architectures for Implementing Achievement Badges - Practical Experiences},
 booktitle = {Proceedings of the 2014 International Conference on Teaching and Learning in Computing and Engineering},
 series = {LATICE '14},
 year = {2014},
 isbn = {978-1-4799-3592-5},
 pages = {41--46},
 numpages = {6},
 url = {http://dx.doi.org/10.1109/LaTiCE.2014.16},
 doi = {10.1109/LaTiCE.2014.16},
 acmid = {2625255},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {gamification, achievement badges, automated assessment, system design},
 abstract={There are multiple commercial and non-commercial products available to integrate gamification aspects to existing services. Some of these are platform dependent whilst others are more general purpose. Commercial systems come with some problems - for example, lack of control and privacy issues. To avoid these problems, we created two iterations of badge systems and tested both of them on large courses (ca. 300 students each). In this paper, we present these systems and evaluate their merits and flaws. Based on our experiences, we present design principles on how to implement badge systems to existing online learning environments.},
}

@inproceedings{Helminen:2013:SSP:2496033.2497175,
 author = {Helminen, Juha and Ihantola, Petri and Karavirta, Ville and Alaoutinen, Satu},
 title = {How Do Students Solve Parsons Programming Problems?  --  Execution-Based vs. Line-Based Feedback},
 booktitle = {Proceedings of the 2013 Learning and Teaching in Computing and Engineering},
 series = {LATICE '13},
 year = {2013},
 isbn = {978-0-7695-4960-6},
 pages = {55--61},
 numpages = {7},
 url = {http://dx.doi.org/10.1109/LaTiCE.2013.26},
 doi = {10.1109/LaTiCE.2013.26},
 acmid = {2497175},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Parsons Puzzles, Python, Automatic Feedback},
 abstract={In large introductory programming classes, there typically are no resources for adequate individual guidance. Automatic feedback for programming tasks can facilitate students' learning by allowing them to get immediate individual feedback regardless of time and place. This paper presents a study on how the type of automatic feedback in Parsons problems affects how students solve them. Students on their first programming class were divided into two groups and, in two assignments, each group in turn received different type of feedback. The type of feedback had an effect on how students constructed their programs and how quickly they were able to complete them. With feedback based on execution as opposed to the visible arrangement of code, the programs were more frequently executable when feedback was requested and, overall, feedback was requested less frequently. Based on the analysis, we discuss possible future improvements to automatic feedback in this type of an assignment.},
}

@inproceedings{Koskinen:2012:QWP:2411131.2411638,
 author = {Koskinen, Teemu and Ihantola, Petri and Karavirta, Ville},
 title = {Quality of WordPress Plug-Ins: An Overview of Security and User Ratings},
 booktitle = {Proceedings of the 2012 ASE/IEEE International Conference on Social Computing and 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust},
 series = {SOCIALCOM-PASSAT '12},
 year = {2012},
 isbn = {978-0-7695-4848-7},
 pages = {834--837},
 numpages = {4},
 url = {http://dx.doi.org/10.1109/SocialCom-PASSAT.2012.31},
 doi = {10.1109/SocialCom-PASSAT.2012.31},
 acmid = {2411638},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {wordpress, plugins, security, user ratings, static analysis},
 abstract={We have applied static analysis to find out how vulnerable the plugins available at the official Word Press plug in directory are to well known security exploits. We have compared the amount of potential vulnerabilities and vulnerability density to the user ratings, to determine if user ratings can be used for finding secure plugins. We conclude that the quality of the plugins varies and there is no clear correlation between the ratings of plugins and the number of vulnerabilities detected in them. Indeed, an additional manual review exposed a simple but severe SQL injection vulnerability in a plug in, which has both good user ratings and a high download count. We recommend plugins to be individually inspected for typical vulnerabilities before using them in any Word Press powered site.},
} 